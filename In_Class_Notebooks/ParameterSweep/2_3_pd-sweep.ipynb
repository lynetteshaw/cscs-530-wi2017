{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCS530 Winter 2017\n",
    "#### Complex Systems 530 - Computer Modeling of Complex Systems (Winter 2017)\n",
    "\n",
    "  * Course ID: CMPLXSYS 530\n",
    "  * Course Title: Computer Modeling of Complex Systems\n",
    "  * Term: Winter 2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PD (Game Theory) Model\n",
    "\n",
    "In this notebook, we implement a very simple \"Prisoner's Dilemma\" model using two different types of players and demonstrate how to run a parameter sweep for the model.\n",
    "\n",
    "For more information on the Prisoner's Dilemma and its application to real world topics, see https://en.wikipedia.org/wiki/Prisoner's_dilemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy.random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payoff Structure\n",
    "\n",
    "In a Prisoner's Dilemma, players choose whether to remain silent (\"Cooperate\") or confess (\"Defect\"). The best collective outcome is for both prisoners to Cooperate, while the best individual outcome is to Defect while the other player Cooperates. \n",
    "\n",
    "This structure for the game can be represented using a payoff map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup payoffs\n",
    "payoff_map = {(\"C\", \"C\"): (-1, -1),\n",
    "             (\"C\", \"D\"): (-10, 0),\n",
    "             (\"D\", \"C\"): (0, -10),\n",
    "             (\"D\", \"D\"): (-4, -4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_payoff, your_payoff = payoff_map[(\"D\", \"C\")]\n",
    "print(\"I got {0}\".format(my_payoff))\n",
    "print(\"You got {0}\".format(your_payoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Types\n",
    "\n",
    "In the case of an \"Iterated PD,\" players play one another for a repeated set of PD games with the goal of maximizing their long-term payoff. A host of potential strategies can be used to decide what to play in a given round. Here we consider only two.\n",
    "\n",
    "* __Simple Probabilistic__ : This simple player chooses to \"Defect\" on any given round according to some exogeneously specified probability. No learning from prior experiences is involved.\n",
    "\n",
    "\n",
    "      \n",
    "* __Cooperate Until Other Player Defects__ : This player chooses to \"Cooperate\" until the other player first \"Defects,\" after which point she will \"Defect.\" The number of rounds the player continues to Defect for after this point can be adjusted by specifying how long her memory of interactions is.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Player(object):\n",
    "    \"\"\"\n",
    "    Player object.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, payoff_map, prob_confess):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        self.payoff_map = payoff_map\n",
    "        self.prob_confess = prob_confess\n",
    "        self.previous_game_payoffs = []\n",
    "        self.other_player_action = []\n",
    "        \n",
    "    def get_action(self):\n",
    "        \"\"\"\n",
    "        Randomly draw action given prob_confess.\n",
    "        \"\"\"\n",
    "        if numpy.random.random() <= self.prob_confess:\n",
    "            return \"D\"\n",
    "        else:\n",
    "            return \"C\"\n",
    "        \n",
    "\n",
    "class AlwaysCUntilDPlayer(object):\n",
    "    \"\"\"\n",
    "    Always cooperates until the other defects.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, payoff_map, memory=None):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        self.payoff_map = payoff_map\n",
    "        self.memory = memory\n",
    "        self.previous_game_payoffs = []\n",
    "        self.other_player_action = []\n",
    "        \n",
    "    def get_action(self):\n",
    "        \"\"\"\n",
    "        Randomly draw action given prob_confess.\n",
    "        \"\"\"\n",
    "        if self.memory: \n",
    "            if self.other_player_action[(-self.memory):].count(\"D\") > 0:\n",
    "                return \"D\"\n",
    "            else:\n",
    "                return \"C\"\n",
    "        else:\n",
    "            if self.other_player_action.count(\"D\") > 0:\n",
    "                return \"D\"\n",
    "            else:\n",
    "                return \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_a = Player(payoff_map, .5)\n",
    "player_a.get_action()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### The Game\n",
    "\n",
    "Having specified our players, we can then use another Class for the Game itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Game(object):\n",
    "    \"\"\"\n",
    "    Game class which stores the two players, their actions, and outcome.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, player_a, player_b):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        self.player_a = player_a\n",
    "        self.player_b = player_b\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Run the game.\n",
    "        \"\"\"\n",
    "        # Draw the actions of the players\n",
    "        self.action_a = self.player_a.get_action()\n",
    "        self.action_b = self.player_b.get_action()\n",
    "        \n",
    "        # Calculate the outcomes\n",
    "        self.payoff_a, self.payoff_b = payoff_map[(self.action_a, self.action_b)]\n",
    "        self.total_payoff = self.payoff_a + self.payoff_b\n",
    "        self.average_payoff = (self.payoff_a + self.payoff_b) / 2.0\n",
    "        \n",
    "        # Update player memories\n",
    "        self.player_a.previous_game_payoffs.append(self.payoff_a)\n",
    "        self.player_b.previous_game_payoffs.append(self.payoff_b)\n",
    "        self.player_a.other_player_action.append(self.action_b)\n",
    "        self.player_b.other_player_action.append(self.action_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Example of single Game and its outcome\n",
    "\n",
    "# Create players\n",
    "player_a = Player(payoff_map, prob_confess = .5)\n",
    "player_b = AlwaysCUntilDPlayer(payoff_map, memory = 5)\n",
    "\n",
    "# Create the game\n",
    "g = Game(player_a, player_b)\n",
    "\n",
    "# Run the game\n",
    "g.run()\n",
    "\n",
    "print(\"The strategies were {0}, {1}\".format(g.action_a, g.action_b))\n",
    "print(\"The total payoff was {0} and the average payoff was {1}\"\\\n",
    "        .format(g.total_payoff, g.average_payoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterated PD\n",
    "\n",
    "We can now set up an iterated PD using a For loop to run through them and create histories of the individual game plays and total payoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set number of games to run\n",
    "num_games = 100\n",
    "game_history = []\n",
    "total_payoff_history = []\n",
    "\n",
    "# Create players\n",
    "player_a = Player(payoff_map, .5)\n",
    "player_b = AlwaysCUntilDPlayer(payoff_map, 5)\n",
    "\n",
    "for i in range(num_games):\n",
    "    # Create and run the game\n",
    "    g = Game(player_a, player_b)\n",
    "    g.run()\n",
    "    \n",
    "    # Append to the history\n",
    "    total_payoff_history.append(g.total_payoff)\n",
    "    game_history.append(g)\n",
    "\n",
    "## Plot payoff history \n",
    "_ = plt.hist(total_payoff_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at a series of plays \n",
    "\n",
    "[(g.action_a , g.action_b) for g in game_history[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Sweep\n",
    "\n",
    "We can now create a parameter sweep for different values of \"Probability of Confessing\" and \"Memory Length\" using nested loops. Note, this only considers a single, 100 game-length iterated PD for each parameter setting. Given your analysis goals, this might be an insufficient number to reliably characterize your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set number of games to run\n",
    "num_games = 100\n",
    "game_history = []\n",
    "total_payoff_history = []\n",
    "\n",
    "\n",
    "# Setup values for parameter sweep\n",
    "player_a_prob_confess_values = [0.01, 0.1, 0.5, 0.9]\n",
    "player_b_memory_values = [1, 5, 10, 15, 20]\n",
    "\n",
    "\n",
    "# Parameter sweep\n",
    "\n",
    "for player_a_prob_confess in player_a_prob_confess_values:\n",
    "    for player_b_memory in player_b_memory_values:\n",
    "        # Create players\n",
    "        player_a = Player(payoff_map, player_a_prob_confess)\n",
    "        player_b = AlwaysCUntilDPlayer(payoff_map, player_b_memory)\n",
    "\n",
    "        for i in range(num_games):\n",
    "            # Create and run the game\n",
    "            g = Game(player_a, player_b)\n",
    "            g.run()\n",
    "\n",
    "            # Append to the history\n",
    "            total_payoff_history.append((player_a_prob_confess, player_b_memory, g.total_payoff))\n",
    "            game_history.append(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Given the output from the parameter sweep, we can now undetake some basic analysis of our model. Converting the day from a list format to a dataframe makes this a lot easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(total_payoff_history, columns=[\"prob_confess\", \"memory\", \"payoff\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show groupbys in each dimension\n",
    "df.groupby(\"memory\")[\"payoff\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show groupbys in each dimension\n",
    "df.groupby(\"prob_confess\")[\"payoff\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show groupbys in each dimension\n",
    "df.groupby([\"prob_confess\", \"memory\"])[\"payoff\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Joint and unstack\n",
    "df.groupby([\"prob_confess\", \"memory\"])[\"payoff\"].mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Joint and unstack\n",
    "payoff_surface = df.groupby([\"prob_confess\", \"memory\"])[\"payoff\"].mean().unstack()\n",
    "\n",
    "# Plot surface\n",
    "\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "plt.contourf(payoff_surface.columns, payoff_surface.index, payoff_surface, cmap = \"Spectral\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Effect on probability of confession and memory on payoff\", fontsize=16)\n",
    "plt.ylabel(\"Probability of confession for player A\", fontsize=16)\n",
    "_ = plt.xlabel(\"Memory length for player B\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write dataframe to file\n",
    "\n",
    "df.to_csv(\"pd_sweep.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2014, Michael Bommarito All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "- Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "\n",
    "- Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
